<!DOCTYPE HTML>
<html lang="en">
  
<head>
  <meta name=viewport content=“width=800”>
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
  <style type="text/css">
    @import url('https://fonts.googleapis.com/css2?family=Ubuntu:ital,wght@0,300;0,400;0,500;0,700;1,300;1,400;1,500;1,700&display=swap');
      /* Color scheme stolen from Sergey Karayev */
      a {
      color: #B83A4B;
      text-decoration:none;
      }
      a:focus, a:hover {
      color: #f09228;
      text-decoration:none;
      }
      body,td,th,tr,p,a {
      font-family: 'Ubuntu', sans-serif;
      font-size: 15px;
      font-weight: 400;
      font-style: normal;
      }
      strong {
      font-family: 'Ubuntu', sans-serif;
      font-size: 15px;
      font-weight: 500;
      font-style: normal;
      }
      heading {
      font-family: 'Ubuntu', sans-serif;
      font-size: 24px;
      font-weight: 500;
      font-style: normal;
      }
      papertitle {
      font-family: 'Ubuntu', sans-serif;
      font-size: 15px;
      font-weight:500;
      font-style: normal;
      }
      name {
      font-family: 'Ubuntu', sans-serif;
      font-weight: 400;
      font-size: 32px;
      font-style: normal;
      }
      .one
      {
      width: 160px;
      height: 140px;
      position: relative;
      }
      .two
      {
      width: 160px;
      height: 160px;
      position: absolute;
      transition: opacity .2s ease-in-out;
      -moz-transition: opacity .2s ease-in-out;
      -webkit-transition: opacity .2s ease-in-out;
      }
      .fade {
       transition: opacity .2s ease-in-out;
       -moz-transition: opacity .2s ease-in-out;
       -webkit-transition: opacity .2s ease-in-out;
      }
      span.highlight {
          background-color: #ffffd0;
      }
  </style>
  <link rel="icon" type="image/png" href="media/preview.jpg">
  <title>Sayan Deb Sarkar - Homepage</title>
  <meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
  <script src="script/functions.js"></script>
</head>

<body>
  <table width="1000" border="0" align="center" cellspacing="0" cellpadding="0">
    <tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Sayan Deb Sarkar</name>
              </p>
              <p>I am a first-year PhD student at Stanford University in <a href="https://gradientspaces.stanford.edu/">Gradient Spaces Group</a>, 
                advised by Prof. <a href="https://ir0.github.io/">Iro Armeni</a>, 
                affiliated with <a href="https://svl.stanford.edu/">Stanford Vision Lab (SVL)</a>.
              <p>
                Before starting PhD, I was a CS master student at <a href="https://ethz.ch/en.html">ETH Zürich</a> supervised by Prof. <a href="https://people.inf.ethz.ch/marc.pollefeys/">Marc Pollefeys</a>, working on 
                aligning real-world 3D environments from multi-modal data. I graduated with a Bachelors in 
                Information Technology from Manipal University, India, where I spent time working on face recognition and medical imaging problems.
              </p>

              <p>
                In 2020-21, I spent a wonderful time working with <a href="https://shreyashampali.github.io/">Shreyas Hampali</a>, 
                <a href="https://vevenom.github.io/">Sinisa Stekovic</a> and <a href="https://radmahdi.github.io/Home.html">Mahdi Rad</a> at 
                Prof. <a href="https://vincentlepetit.github.io/">Vincent Lepetit</a>'s 
                lab on hand-object pose estimation and monte carlo scene search for 3D scene understanding. 
                I view them as mentors as entering research, and strive to learn from them.
              </p>

              <p>

              </p>
              
              <!-- <p>
                Before starting MSc, I gained experience working as a Computer Vision Research Engineer at <strong>Mercedes-Benz R&D</strong>,
                on Intelligent Interior Camera Systems, for around a year, and as a Research Assistant for the
                other one and a half years with <a href="https://vincentlepetit.github.io/">Prof. 
                Vincent Lepetit</a> at the <strong>Institute of Computer Graphics and Vision, TU Graz</strong>.
                My work has been published multiple times in top-tier Vision conferences such as CVPR, ICCV and ECCV.
              </p> -->
              <p>
                I am always looking for interesting research collaborations, get in touch if you have something relevant. 
                If you're in or around the Bay Area, feel free to reach out, I am always up for a good cup of coffee!
              </p>
              <p style="text-align:center">
                <a href="mailto:sdsarkar@stanford.edu">Email</a> &nbsp/&nbsp
                <a href="data/Resume_SayanDebSarkar.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=T9zPzwoAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/sayands/">Github</a> &nbsp/&nbsp
                <a href="https://twitter.com/debsarkar_sayan">Twitter</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/sayands/">LinkedIn</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <img style="width:100%;max-width:100%" alt="profile photo" src="images/sayandebsarkar.jpg" class="hoverZoomLink">
            </td>
          </tr>
        </tbody></table>

        <!-- NEWS -->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <heading>News</heading>
                <ul>
                  <li style="margin: 5px;"><strong>2024-09</strong> I joined <a href="https://www.stanford.edu/">Stanford University</a> for PhD in Computer Vision!</li>
                  <li style="margin: 5px;"><strong>2023-08</strong> I will be a research intern at Qualcomm XR Labs, Amsterdam for the Fall!</li>
                  <li style="margin: 5px;"><strong>2023-07</strong> <a href="https://sayands.github.io/sgaligner/">SGAligner</a> accepted to ICCV 2023. First <strong>first-author</strong> submission, first accept! </li>
                  <li style="margin: 5px;"><strong>2022-09</strong> I started Computer Science MSc at ETH Zurich! </li>
                  <li style="margin: 5px;"><strong>2022-07</strong> <a href="https://arxiv.org/abs/2104.14639">Keypoint Transformer</a> accepted as <strong>Oral</strong> 
                    at CVPR 2022!
                  <li style="margin: 5px;"><strong>2021-05</strong> I started at <strong>Mercedes-Benz R & D</strong> as a Computer Vision Research Engineer! </li>
                  <a href="javascript:void(0);" onclick="toggleBlock('old_news')">---- show more ----</a>
                  <div id="old_news" style="display: none;">
                    <li style="margin: 5px;"><strong>2021-03</strong> <a href="https://arxiv.org/abs/2103.07969">MCSS</a> accepted at CVPR 2021! </li>
                      <li><strong>2020-06</strong> <a href="https://arxiv.org/abs/2001.02149">General 3D Room Layout from a Single View by Render-and-Compare
                      </a> accepted at ECCV 2020! </li>
                      <li style="margin: 5px;"><strong>2020-01</strong> I started as a Research Assistant at ICG, TU Graz with 
                        Prof. <a href="https://vincentlepetit.github.io/">Vincent Lepetit</a>, supported by a Qualcomm fellowship!</li>
                  </div>
                </div></div>
                </ul>
              </td>
            </tr>
        </tbody></table>

        <!-- PUBLICATIONS -->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
            <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <heading>Research</heading>
                <p>
                  My research interests lie at the intersection 
                of Computer Vision and Machine Learning, specifically in the areas of 3D scene understanding and pose estimation. 
                </p>
                
              </p>
              </td>
            </tr>
          </tbody>
        </table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
            <tr onmouseout="clipnerf_stop()" onmouseover="clipnerf_start()" bgcolor="#ffffd0">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="three">
                  <img src='images/sgaligner_teaser.png' width="160">
                </div>
                <script type="text/javascript">
                  function clipnerf_start() {
                    document.getElementById('clipnerf_image').style.opacity = "1";
                  }

                  function clipnerf_stop() {
                    document.getElementById('clipnerf_image').style.opacity = "0";
                  }
                  clipnerf_stop()
                </script>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                  <papertitle>SGAligner : 3D Scene Alignment with Scene Graphs</papertitle>
                <br>
                <strong>Sayan Deb Sarkar</strong>, Ondrej Miksik, Marc Pollefeys, Daniel Barath, Iro Armeni
                <!-- <br> -->
                <br>
                <a href="https://arxiv.org/pdf/2304.14880/pdf">arXiv</a> /        
                <a href="https://sayands.github.io/sgaligner/">Project Page</a> /
                <a href="https://youtu.be/nBTyZyY9X7I">Video</a> /
                <a href="https://github.com/sayands/sgaligner">Code</a>
                <br>
                <em> International Conference on Computer Vision (ICCV), 2023 </em>
                <br>
              
                <p></p>
                <p>
                  We focus on the fundamental problem of aligning pairs of 3D scene graphs whose overlap can range from
                  zero to partial and can contain arbitrary changes. We propose SGAligner, the first method for aligning 
                  pairs of 3D scene graphs that is robust to in-the-wild scenarios.
                  </p>
              </td>
            </tr> 

            <tr onmouseout="clipnerf_stop()" onmouseover="clipnerf_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <img src='images/handsformer_arvix.png' width="160">
                </div>
                <script type="text/javascript">
                  function clipnerf_start() {
                    document.getElementById('clipnerf_image').style.opacity = "1";
                  }

                  function clipnerf_stop() {
                    document.getElementById('clipnerf_image').style.opacity = "0";
                  }
                  clipnerf_stop()
                </script>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                  <papertitle>Keypoint Transformer: Solving Joint Identification in Challenging Hands and Object Interactions for Accurate 3D Pose Estimation</papertitle>
                <br>
                Shreyas Hampali, <strong>Sayan Deb Sarkar</strong>, Mahdi Rad, Vincent Lepetit
                <br>
                <em>Computer Vision and Pattern Recognition (CVPR), 2022 <strong>Oral</strong></em>
                <br>
                <a href="https://arxiv.org/pdf/2104.14639.pdf">arXiv</a> /        
                <a href="https://www.tugraz.at/index.php?id=57823">Project Page</a> /
                <a href="https://www.youtube.com/watch?v=D9YjoJnj_M4">Video</a> /
                <a href="https://github.com/shreyashampali/kypt_transformer">Code</a>
              
                <p></p>
                <p> We propose an efficient network architecture for estimating pose of two hands and object during complex interaction. We also release the challenging H2O-3D dataset, which contains two hands interacting with YCB objects. </p>
              </td>
            </tr> 

            <tr onmouseout="clipnerf_stop()" onmouseover="clipnerf_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <img src='images/mcss_cvpr21.png' width="160">
                </div>
                <script type="text/javascript">
                  function clipnerf_start() {
                    document.getElementById('clipnerf_image').style.opacity = "1";
                  }

                  function clipnerf_stop() {
                    document.getElementById('clipnerf_image').style.opacity = "0";
                  }
                  clipnerf_stop()
                </script>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                  <papertitle>Monte Carlo Scene Search for 3D Scene Understanding</papertitle>
                <br>
                Shreyas Hampali*, Sinisa Stekovic*, <strong>Sayan Deb Sarkar</strong>, Chetan Srinivasa Kumar, Friedrich Fraundorfer, Vincent Lepetit
                <br>
                <em>Computer Vision and Pattern Recognition (CVPR), 2021</em>
                <br>
                <a href="https://arxiv.org/pdf/2103.07969.pdf">arXiv </a> /
                <a href="https://www.tugraz.at/index.php?id=50484">Project Page</a> /
                <a href="https://www.youtube.com/watch?v=4kAfuymevUw&feature=youtu.be">Video</a> /
                <a href="https://github.com/montescene">Code</a>
                <p></p>
                <p> We propose a Monte-Carlo Tree Search (MCTS) based analysis-by-synthesis method to recover complete scene (3D layout+objects) from a RGB-D scan of the environment. <br> 
                 <em>*Equal contribution</em> </p>
              </td>
            </tr>

            <tr onmouseout="clipnerf_stop()" onmouseover="clipnerf_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <img src='images/roomlayout_eccv2020.png' width="160">
                </div>
                <script type="text/javascript">
                  function clipnerf_start() {
                    document.getElementById('clipnerf_image').style.opacity = "1";
                  }

                  function clipnerf_stop() {
                    document.getElementById('clipnerf_image').style.opacity = "0";
                  }
                  clipnerf_stop()
                </script>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                  <papertitle>General 3D Room Layout from a Single View by Render-and-Compare</papertitle>
                <br>
                Sinisa Stekovic, Shreyas Hampali, Mahdi Rad, <strong>Sayan Deb Sarkar</strong>, Friedrich Fraundorfer, Vincent Lepetit
                <br>
                <em>European Conference on Computer Vision (ECCV), 2020</em>
                <br>
                <a href="https://arxiv.org/pdf/2001.02149.pdf">arXiv </a> /
                <a href="https://www.tugraz.at/institute/icg/research/team-lepetit/research-projects/general-3d-room-layout-from-a-single-view-by-render-and-compare/">Project Page</a> /
                <a href="https://youtu.be/ZLNnGNzzE7k">Video </a> /
                <a href="https://github.com/vevenom/RoomLayout3D_RandC">Code</a>
                <p></p>
                <p> We propose an analysis-by-synthesis method to estimate a 3D layout of the room - walls, floors, ceilings - from a single perspective view. The method recovers complex non-cubiod layouts by solving a constrained discrete optimization problem. </p>
              </td>
            </tr>

        </tbody> </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Course Projects</heading>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>  
        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <a href="images/final_scene_cg_as22.png"><img src="images/final_scene_cg_as22.png" alt="prl" width="160"></a></td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <p>
          <p>
            <a href="https://sayands.github.io/computer-graphics-project-report/">
            <papertitle>Ray Tracing</papertitle>
            </a>
            <br>
            <em> <a href="https://cgl.ethz.ch/teaching/cg22/home.php">Computer Graphics Rendering Competition</a>, Autumn Semester 2022 </em>
          </p>
          <p>
            Implemented a ray tracer with functionalities such as advanced camera models, participating media, photon mapping, Disney BRDF, etc on the 
            <strong>Nori</strong> framework. 
          </p>
          </p>
          </td>
        </tr>
        
        </tbody></table>
        
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Misc</heading>
            <p>
              <li style="margin: 5px;"> 
                <b>Workshop Organisation:</b> <a href="https://cv4aec.github.io/">CV4AEC@CVPR</a>
              </li>
              <li style="margin: 5px;"> 
                <b>Conference Review:</b> CVPR, ICCV, ECCV
              </li>
            </p>
          </td>
          </tr>
        </table>

      </td>
    </tr>
  </table>

  <center>
    <p>
        &copy; Sayan Deb Sarkar | Last updated: Sept 23rd, 2024 | <a href="https://jonbarron.info/">Website Template</a>
    </p>
  </center>


</body>

</html>

<script>
  function toggleBlock(blockId) {
    var block = document.getElementById(blockId);
    if (block.style.display === 'none') {
      block.style.display = 'block';
    } else {
      block.style.display = 'none';
    }
  }
</script>
